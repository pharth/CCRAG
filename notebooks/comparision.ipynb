{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Simple RAG vs Contextual RAG\n",
    "\n",
    "This notebook compares the performance of our two RAG implementations:\n",
    "1. Simple RAG: Basic document retrieval and question answering\n",
    "2. Contextual RAG: Enhanced retrieval with document context and conversation history\n",
    "\n",
    "We'll use sample documents and evaluate both systems on various question types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add project to path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Both RAG Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from simple_rag.modules.embedding import init_embeddings as simple_init_embeddings, init_llm as simple_init_llm\n",
    "from simple_rag.modules.pdf_loader import PDFProcessor\n",
    "from simple_rag.modules.qa_chain import QAChain as SimpleQAChain\n",
    "\n",
    "from contextual_rag.modules.embedding import init_embeddings as contextual_init_embeddings, init_llm as contextual_init_llm\n",
    "from contextual_rag.modules.pdf_loader import ContextualPDFProcessor\n",
    "from contextual_rag.modules.qa_chain import ContextualQAChain\n",
    "\n",
    "# PDF path - adjust this to your document(s)\n",
    "pdf_path = \"../data/mirage/sample_document.pdf\"  # Update with your actual document path\n",
    "\n",
    "# Initialize Simple RAG\n",
    "simple_embeddings = simple_init_embeddings()\n",
    "simple_llm = simple_init_llm()\n",
    "simple_processor = PDFProcessor(simple_embeddings, persist_directory=\"../vector_db/simple\")\n",
    "if os.path.exists(pdf_path):\n",
    "    simple_processor.load_and_process(pdf_path)\n",
    "    simple_qa = SimpleQAChain(simple_processor.vector_store, simple_llm)\n",
    "else:\n",
    "    print(f\"Warning: File {pdf_path} not found.\")\n",
    "\n",
    "# Initialize Contextual RAG\n",
    "contextual_embeddings = contextual_init_embeddings()\n",
    "contextual_llm = contextual_init_llm()\n",
    "contextual_processor = ContextualPDFProcessor(contextual_embeddings, contextual_llm, persist_directory=\"../vector_db/contextual\")\n",
    "if os.path.exists(pdf_path):\n",
    "    contextual_processor.load_and_process(pdf_path)\n",
    "    contextual_qa = ContextualQAChain(contextual_processor.vector_store, contextual_llm)\n",
    "else:\n",
    "    print(f\"Warning: File {pdf_path} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Test Questions\n",
    "\n",
    "We'll test various types of questions to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample questions - update these based on your document content\n",
    "test_questions = [\n",
    "    \"What is the main topic of the document?\",\n",
    "    \"Can you summarize the key points?\",\n",
    "    \"What are the conclusions presented?\",\n",
    "    # Add more questions specific to your document\n",
    "]\n",
    "\n",
    "# For contextual RAG conversation history test\n",
    "conversation_questions = [\n",
    "    \"What is discussed in the introduction?\",\n",
    "    \"What comes after that?\",\n",
    "    \"Can you provide more details about it?\",\n",
    "    \"What are the implications of this?\"\n",
    "    # The last three questions are deliberately vague to test contextual understanding\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Simple and Contextual RAG on Basic Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "results = []\n",
    "\n",
    "for question in test_questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    \n",
    "    # Simple RAG answer\n",
    "    simple_answer = simple_qa.generate_answer(question)\n",
    "    print(f\"\\nSimple RAG Answer:\\n{simple_answer}\")\n",
    "    \n",
    "    # Contextual RAG answer\n",
    "    contextual_answer = contextual_qa.generate_answer(question)\n",
    "    print(f\"\\nContextual RAG Answer:\\n{contextual_answer}\")\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Question\": question,\n",
    "        \"Simple RAG\": simple_answer,\n",
    "        \"Contextual RAG\": contextual_answer\n",
    "    })\n",
    "\n",
    "# Create DataFrame for comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Contextual RAG with Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test conversation with contextual understanding\n",
    "conversation_history = []\n",
    "\n",
    "for i, question in enumerate(conversation_questions):\n",
    "    print(f\"\\nQ{i+1}: {question}\")\n",
    "    \n",
    "    # Get answer with conversation history\n",
    "    answer = contextual_qa.generate_answer(question, conversation_history)\n",
    "    print(f\"A{i+1}: {answer}\")\n",
    "    \n",
    "    # Update conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Retrieval Quality\n",
    "\n",
    "Let's compare the quality of document chunks retrieved by both systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample question for retrieval analysis\n",
    "test_question = \"What is the main topic of the document?\"\n",
    "\n",
    "# Get retrieved documents from Simple RAG\n",
    "simple_docs = simple_qa.retriever.get_relevant_documents(test_question)\n",
    "print(f\"Simple RAG retrieved {len(simple_docs)} documents\")\n",
    "\n",
    "# Get retrieved documents from Contextual RAG\n",
    "contextual_docs = contextual_qa._get_context(test_question)\n",
    "print(f\"Contextual RAG context length: {len(contextual_docs)}\")\n",
    "\n",
    "# Print first retrieved document from each system\n",
    "print(\"\\nSimple RAG first retrieved document:\")\n",
    "if simple_docs:\n",
    "    print(simple_docs[0].page_content[:300], \"...\")\n",
    "\n",
    "print(\"\\nContextual RAG retrieved context (sample):\")\n",
    "print(contextual_docs[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "Based on our tests, we can analyze the performance of both systems:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages of Simple RAG\n",
    "- Faster processing time\n",
    "- Less computational overhead\n",
    "- Simpler implementation\n",
    "- Works well for straightforward, single-turn questions\n",
    "\n",
    "### Advantages of Contextual RAG\n",
    "- Better understanding of document context\n",
    "- Improved handling of ambiguous queries\n",
    "- Support for conversation history\n",
    "- More coherent multi-turn interactions\n",
    "- Better for complex document understanding\n",
    "\n",
    "### Recommendations\n",
    "- Use Simple RAG for: Basic QA, single-turn interactions, simpler documents\n",
    "- Use Contextual RAG for: Complex documents, multi-turn conversations, ambiguous queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}